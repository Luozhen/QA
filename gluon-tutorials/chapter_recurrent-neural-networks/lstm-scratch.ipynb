{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 长短期记忆（LSTM）--- 从0开始\n",
    "\n",
    "[上一节](bptt.md)中，我们介绍了循环神经网络中的梯度计算方法。我们发现，循环神经网络的隐含层变量梯度可能会出现衰减或爆炸。虽然[梯度裁剪](rnn-scratch.md)可以应对梯度爆炸，但无法解决梯度衰减的问题。因此，给定一个时间序列，例如文本序列，循环神经网络在实际中其实较难捕捉两个时刻距离较大的文本元素（字或词）之间的依赖关系。\n",
    "\n",
    "为了更好地捕捉时序数据中间隔较大的依赖关系，我们介绍了一种常用的门控循环神经网络，叫做[门控循环单元](gru-scratch.md)。本节将介绍另一种常用的门控循环神经网络，长短期记忆（long short-term memory，简称LSTM）。它由Hochreiter和Schmidhuber在1997年被提出。事实上，它比门控循环单元的结构稍微更复杂一点。\n",
    "\n",
    "\n",
    "## 长短期记忆\n",
    "\n",
    "我们先介绍长短期记忆的构造。长短期记忆的隐含状态包括隐含层变量$\\mathbf{H}$和细胞$\\mathbf{C}$（也称记忆细胞）。它们形状相同。\n",
    "\n",
    "\n",
    "### 输入门、遗忘门和输出门\n",
    "\n",
    "\n",
    "假定隐含状态长度为$h$，给定时刻$t$的一个样本数为$n$特征向量维度为$x$的批量数据$\\mathbf{X}_t \\in \\mathbb{R}^{n \\times x}$和上一时刻隐含状态$\\mathbf{H}_{t-1} \\in \\mathbb{R}^{n \\times h}$，输入门（input gate）$\\mathbf{I}_t \\in \\mathbb{R}^{n \\times h}$、遗忘门（forget gate）$\\mathbf{F}_t \\in \\mathbb{R}^{n \\times h}$和输出门（output gate）$\\mathbf{O}_t \\in \\mathbb{R}^{n \\times h}$的定义如下：\n",
    "\n",
    "$$\\mathbf{I}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xi} + \\mathbf{H}_{t-1} \\mathbf{W}_{hi} + \\mathbf{b}_i)$$\n",
    "\n",
    "$$\\mathbf{F}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xf} + \\mathbf{H}_{t-1} \\mathbf{W}_{hf} + \\mathbf{b}_f)$$\n",
    "\n",
    "$$\\mathbf{O}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xo} + \\mathbf{H}_{t-1} \\mathbf{W}_{ho} + \\mathbf{b}_o)$$\n",
    "\n",
    "其中的$\\mathbf{W}_{xi}, \\mathbf{W}_{xf}, \\mathbf{W}_{xo} \\in \\mathbb{R}^{x \\times h}$和$\\mathbf{W}_{hi}, \\mathbf{W}_{hf}, \\mathbf{W}_{ho} \\in \\mathbb{R}^{h \\times h}$是可学习的权重参数，$\\mathbf{b}_i, \\mathbf{b}_f, \\mathbf{b}_o \\in \\mathbb{R}^{1 \\times h}$是可学习的偏移参数。函数$\\sigma$自变量中的三项相加使用了[广播](../chapter_crashcourse/ndarray.md)。\n",
    "\n",
    "和[门控循环单元](gru-scratch.md)中的重置门和更新门一样，这里的输入门、遗忘门和输出门中每个元素的值域都是$[0, 1]$。\n",
    "\n",
    "\n",
    "### 候选细胞\n",
    "\n",
    "和[门控循环单元](gru-scratch.md)中的候选隐含状态一样，长短期记忆中的候选细胞$\\tilde{\\mathbf{C}}_t \\in \\mathbb{R}^{n \\times h}$也使用了值域在$[-1, 1]$的双曲正切函数tanh做激活函数：\n",
    "\n",
    "$$\\tilde{\\mathbf{C}}_t = \\text{tanh}(\\mathbf{X}_t \\mathbf{W}_{xc} + \\mathbf{H}_{t-1} \\mathbf{W}_{hc} + \\mathbf{b}_c)$$\n",
    "\n",
    "其中的$\\mathbf{W}_{xc} \\in \\mathbb{R}^{x \\times h}$和$\\mathbf{W}_{hc} \\in \\mathbb{R}^{h \\times h}$是可学习的权重参数，$\\mathbf{b}_c \\in \\mathbb{R}^{1 \\times h}$是可学习的偏移参数。\n",
    "\n",
    "\n",
    "### 细胞\n",
    "\n",
    "我们可以通过元素值域在$[0, 1]$的输入门、遗忘门和输出门来控制隐含状态中信息的流动：这通常可以应用按元素乘法符$\\odot$。当前时刻细胞$\\mathbf{C}_t \\in \\mathbb{R}^{n \\times h}$的计算组合了上一时刻细胞和当前时刻候选细胞的信息，并通过遗忘门和输入门来控制信息的流动：\n",
    "\n",
    "$$\\mathbf{C}_t = \\mathbf{F}_t \\odot \\mathbf{C}_{t-1} + \\mathbf{I}_t \\odot \\tilde{\\mathbf{C}}_t$$\n",
    "\n",
    "需要注意的是，如果遗忘门一直近似1且输入门一直近似0，过去的细胞将一直通过时间保存并传递至当前时刻。这个设计可以应对循环神经网络中的梯度衰减问题，并更好地捕捉时序数据中间隔较大的依赖关系。\n",
    "\n",
    "\n",
    "### 隐含状态\n",
    "\n",
    "有了细胞以后，接下来我们还可以通过输出门来控制从细胞到隐含层变量$\\mathbf{H}_t \\in \\mathbb{R}^{n \\times h}$的信息的流动：\n",
    "\n",
    "$$\\mathbf{H}_t = \\mathbf{O}_t \\odot \\text{tanh}(\\mathbf{C}_t)$$\n",
    "\n",
    "需要注意的是，当输出门近似1，细胞信息将传递到隐含层变量；当输出门近似0，细胞信息只自己保留。\n",
    "\n",
    "\n",
    "\n",
    "输出层的设计可参照[循环神经网络](rnn-scratch.md)中的描述。\n",
    "\n",
    "\n",
    "## 实验\n",
    "\n",
    "\n",
    "为了实现并展示门控循环单元，我们依然使用周杰伦歌词数据集来训练模型作词。这里除长短期记忆以外的实现已在[循环神经网络](rnn-scratch.md)中介绍。\n",
    "\n",
    "\n",
    "### 数据处理\n",
    "\n",
    "我们先读取并对数据集做简单处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('vocab size:', 88)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('../data/jaychou_lyrics.txt.zip', 'r') as zin:\n",
    "    zin.extractall('../data/')\n",
    "\n",
    "with open('../data/jaychou_lyrics.txt') as f:\n",
    "    corpus_chars = f.read()\n",
    "\n",
    "corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "corpus_chars = corpus_chars[0:20000]\n",
    "\n",
    "idx_to_char = list(set(corpus_chars))\n",
    "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "\n",
    "vocab_size = len(char_to_idx)\n",
    "print('vocab size:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用onehot来将字符索引表示成向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inputs(data):\n",
    "    return [nd.one_hot(X, vocab_size) for X in data.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型参数\n",
    "\n",
    "以下部分对模型参数进行初始化。参数`hidden_dim`定义了隐含状态的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Will use', cpu(0))\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# 尝试使用GPU\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from mxnet import nd\n",
    "import utils\n",
    "ctx = utils.try_gpu()\n",
    "print('Will use', ctx)\n",
    "\n",
    "input_dim = vocab_size\n",
    "# 隐含状态长度\n",
    "hidden_dim = 256\n",
    "output_dim = vocab_size\n",
    "std = .01\n",
    "\n",
    "def get_params():\n",
    "    # 输入门参数\n",
    "    W_xi = nd.random_normal(scale=std, shape=(input_dim, hidden_dim), ctx=ctx)\n",
    "    W_hi = nd.random_normal(scale=std, shape=(hidden_dim, hidden_dim), ctx=ctx)\n",
    "    b_i = nd.zeros(hidden_dim, ctx=ctx)\n",
    "    \n",
    "    # 遗忘门参数\n",
    "    W_xf = nd.random_normal(scale=std, shape=(input_dim, hidden_dim), ctx=ctx)\n",
    "    W_hf = nd.random_normal(scale=std, shape=(hidden_dim, hidden_dim), ctx=ctx)\n",
    "    b_f = nd.zeros(hidden_dim, ctx=ctx)\n",
    "    \n",
    "    # 输出门参数\n",
    "    W_xo = nd.random_normal(scale=std, shape=(input_dim, hidden_dim), ctx=ctx)\n",
    "    W_ho = nd.random_normal(scale=std, shape=(hidden_dim, hidden_dim), ctx=ctx)\n",
    "    b_o = nd.zeros(hidden_dim, ctx=ctx)\n",
    "\n",
    "    # 候选细胞参数\n",
    "    W_xc = nd.random_normal(scale=std, shape=(input_dim, hidden_dim), ctx=ctx)\n",
    "    W_hc = nd.random_normal(scale=std, shape=(hidden_dim, hidden_dim), ctx=ctx)\n",
    "    b_c = nd.zeros(hidden_dim, ctx=ctx)\n",
    "\n",
    "    # 输出层\n",
    "    W_hy = nd.random_normal(scale=std, shape=(hidden_dim, output_dim), ctx=ctx)\n",
    "    b_y = nd.zeros(output_dim, ctx=ctx)\n",
    "\n",
    "    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,\n",
    "              b_c, W_hy, b_y]\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "\n",
    "我们将前面的模型公式翻译成代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_rnn(inputs, state_h, state_c, *params):\n",
    "    # inputs: num_steps 个尺寸为 batch_size * vocab_size 矩阵\n",
    "    # H: 尺寸为 batch_size * hidden_dim 矩阵\n",
    "    # outputs: num_steps 个尺寸为 batch_size * vocab_size 矩阵\n",
    "    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,\n",
    "     W_hy, b_y] = params\n",
    "\n",
    "    H = state_h\n",
    "    C = state_c\n",
    "    outputs = []\n",
    "    for X in inputs:        \n",
    "        I = nd.sigmoid(nd.dot(X, W_xi) + nd.dot(H, W_hi) + b_i)\n",
    "        F = nd.sigmoid(nd.dot(X, W_xf) + nd.dot(H, W_hf) + b_f)\n",
    "        O = nd.sigmoid(nd.dot(X, W_xo) + nd.dot(H, W_ho) + b_o)\n",
    "        C_tilda = nd.tanh(nd.dot(X, W_xc) + nd.dot(H, W_hc) + b_c)\n",
    "        C = F * C + I * C_tilda\n",
    "        H = O * nd.tanh(C)\n",
    "        Y = nd.dot(H, W_hy) + b_y\n",
    "        outputs.append(Y)\n",
    "    return (outputs, H, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "\n",
    "下面我们开始训练模型。我们假定谱写歌词的前缀分别为“分开”、“不分开”和“战争中部队”。这里采用的是相邻批量采样实验门控循环单元谱写歌词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20. Training perplexity 9.915488\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe8\\xaf\\xb4\\xe5\\x86\\x8d\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe5\\x86\\x8d\\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3\\xe6\\x8a\\xa1\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe5\\x86\\x8d\\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3\\xe6\\x8a\\xa1\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe5\\x86\\x8d\\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3\\xe6\\x8a')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x88\\xb1\\xe5\\xa5\\xb3\\xe5\\xa5\\xb3\\xe5\\xae\\x83\\xe6\\x83\\xb3\\xe8\\xaf\\xb4\\xe5\\xa4\\xa9\\xe6\\x88\\x91\\xe6\\x96\\xaf\\xe7\\x9a\\x84\\xe5\\x8f\\xaf\\xe7\\x88\\xb1\\xe5\\xa5\\xb3\\xe4\\xba\\xba \\xe5\\x9c\\xa8\\xe6\\x9d\\xa5\\xe4\\xba\\xba\\xe7\\x9a\\x84\\xe5\\xae\\xa9\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe5\\x86\\x8d\\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3\\xe6\\x8a\\xa1\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe5\\x86\\x8d\\xe6')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f\\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3\\xe6\\x8a\\xa1\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe5\\x86\\x8d\\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3\\xe6\\x8a\\xa1\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe5\\x86\\x8d\\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3\\xe6\\x8a\\xa1\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe5\\x86\\x8d\\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\xa6')\n",
      "()\n",
      "Epoch 40. Training perplexity 4.466327\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x88\\xb0 \\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x88\\x91 \\xe8\\xaf\\xb4\\xe5\\xa4\\xa9\\xe8\\xbf\\x99\\xe8\\x89\\xb2 \\xe5\\x9c\\xa8\\xe5\\xb0\\xb1\\xe8\\xbf\\x87\\xe5\\xa8\\x83\\xe5\\x89\\x8d \\xe6\\x9c\\x89\\xe8\\xaf\\x9d\\xe5\\xae\\xa9\\xe8\\xaf\\xb4\\xe8\\xbe\\xb2 \\xe6\\x88\\x91\\xe4\\xb8\\x8d\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3 \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80 \\xe6\\x88\\x91\\xe8\\x83\\xbd\\xe5\\xa4\\x84\\xe6\\x84\\xaf\\xe8\\x8a\\xb2 \\xe5\\x88\\xab\\xe7\\x9d\\x80\\xe4\\xbd\\xa0\\xe8\\xaf\\xb4\\xe5\\x8f\\x88 \\xe6\\x88\\x91\\xe4\\xb8\\x8d\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe6\\x83\\xb3 \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91\\xe4\\xb8\\x8d \\xe6\\x88\\x91')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f \\xe8\\xbf\\x99\\xe6\\x98\\xaf\\xe5\\xb0\\xb1\\xe5\\x9c\\xa8\\xe5\\xbe\\x8e\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe8\\xa8\\x80 \\xe4\\xbd\\xa0\\xe8\\xaf\\xb4\\xe5\\xa5\\xbd\\xe8\\xbf\\x87 \\xe8\\xaf\\xb4\\xe5\\x95\\x95\\xe8\\xbf\\x99\\xe8\\x91\\x97\\xe5\\xa4\\x9f \\xe8\\xbf\\x99\\xe8\\xb7\\xb2\\xe5\\x8f\\xaf\\xe7\\x88\\xb1\\xe5\\xa5\\xb3\\xe4\\xba\\xba \\xe6\\xb8\\xb8\\xe8\\x9f\\xa9\\xe7\\xae\\x80\\xe8\\xae\\xa9\\xe6\\x88\\x91\\xe7\\x9f\\xaf\\xe7\\x8b\\x82\\xe7\\x9a\\x84\\xe5\\x8f\\xaf')\n",
      "()\n",
      "Epoch 60. Training perplexity 2.290182\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x88\\xb0 \\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x92\\x8c\\xe7\\x9a\\x84\\xe6\\xb2\\x9f \\xe4\\xb8\\x80\\xe9\\x83\\xb3\\xe6\\x85\\xaf\\xe7\\xba\\xb5\\xe8\\xbf\\x87 \\xe7\\x84\\xb6\\xe6\\x9d\\xa2\\xe6\\x97\\xa2\\xe7\\x9a\\x84\\xe9\\x97\\xa8\\xe7\\x9a\\x84\\xe9\\xa3\\x9f \\xe4\\xb8\\x80\\xe9\\x83\\xbd\\xe5\\xa4\\xa7\\xe5\\xbf\\x86\\xe6\\x84\\xbf\\xe5\\xbf\\x83\\xe5\\x9c\\x8b\\xe7\\x9a\\x84\\xe6\\x98\\xaf\\xe8\\xa8\\xb2 \\xe6\\x88\\x91\\xe9\\xbb\\x99\\xe9\\xbb\\x98\\xe5\\xbf\\x9c')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80 \\xe7\\x88\\xb1\\xe7\\x8b\\xb6\\xe8\\xae\\xb8\\xe6\\x88\\x91 \\xe5\\xb0\\xb3\\xe5\\x9c\\x89\\xe6\\x89\\x89 \\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe5\\xa4\\x9a\\xe5\\x9c\\xa8\\xe7\\xbe\\x8e\\xe7\\xb4\\xa2\\xe4\\xb8\\x8d\\xe8\\xbe\\xbe\\xe7\\xb1\\xb3\\xe4\\xba\\x9a\\xe5\\xb9\\xb3\\xe5\\x8e\\x9f \\xe7\\xbb\\x99\\xe8\\xbf\\x99\\xe6\\xa0\\xb7\\xe7\\x9a\\x84\\xe7\\x94\\x9f\\xe6\\x97\\xa9\\xe9\\x82\\x97\\xe9\\x83\\xbd\\xe9\\x9a\\xbe\\xe8\\xbf\\x87 \\xe5\\xbf\\x83\\xe7\\x9c\\x8b\\xe7\\x9d\\x80')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f \\xe8\\xaf\\xb4\\xe4\\xbd\\xa0\\xe5\\x9c\\xa8\\xe9\\x82\\x8c\\xe9\\x87\\x8c \\xe5\\x9c\\xa8\\xe5\\xb0\\x8f\\xe6\\x9d\\x91\\xe4\\xb8\\xa4\\xe7\\x97\\xb5 \\xe6\\x98\\xaf\\xe8\\xae\\xa9\\xe6\\xa0\\xb7\\xe7\\x9a\\x84\\xe6\\x89\\xaa \\xe5\\x9c\\xa8\\xe7\\xa7\\xad\\xe5\\xbe\\x85\\xe9\\xa6\\xa8 \\xe5\\x8d\\xb0\\xe5\\xb0\\xb1\\xe6\\x83\\xb3\\xe4\\xb8\\x80\\xe5\\x8f\\x97\\xe6\\x83\\xb3\\xe6\\x80\\xa5 \\xe6\\x88\\x91\\xe6\\x89\\x8b \\xe5\\x88\\xb0\\xe6\\x88\\x91\\xe4\\xb8\\x8d\\xe7')\n",
      "()\n",
      "Epoch 80. Training perplexity 1.504310\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\xbb \\xe6\\x88\\x91\\xe8\\xaf\\xa5\\xe7\\x9a\\x84\\xe7\\x88\\xb1\\xe5\\x86\\x8d\\xe6\\x9c\\x89\\xe8\\xb5\\xbf \\xe5\\xae\\xb6\\xe6\\x96\\xbf\\xe6\\x97\\xb5\\xe7\\x9a\\x84\\xe7\\x9d\\x80\\xe6\\x9c\\xa8\\xe6\\x9d\\xa5 \\xe6\\x88\\x91\\xe8\\x84\\xa9\\xe5\\xa8\\x83\\xe7\\xbe\\x9c\\xe7\\x9d\\xa5\\xe6\\x81\\x85\\xe6\\xad\\x90 \\xe5\\x8d\\xb4\\xe5\\xb0\\xb0\\xe8\\xbf\\x87\\xe9\\x9a\\xbe\\xe9\\xa3\\x93\\xe8\\xbf\\x99\\xe7\\x9a\\x84\\xe8\\xaf\\x81 \\xe5\\xae\\x83\\xe6\\x88\\x9f')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80 \\xe7\\x9a\\x84\\xe7\\xae\\xb8\\xe6\\x88\\x91 \\xe6\\x97\\xa9\\xe9\\x80\\xa3\\xe7\\x9a\\x84\\xe6\\x94\\x9f\\xe6\\x9c\\x89 \\xe5\\x90\\x8e\\xe7\\x9d\\x80\\xe6\\x97\\x8b\\xe8\\x91\\x97\\xe9\\x9a\\x84\\xe9\\xa3\\x8e \\xe4\\xbb\\x80\\xe5\\x8f\\xaa\\xe6\\x88\\x91\\xe5\\xa5\\xb3\\xe7\\x9c\\xa8\\xe7\\x9a\\x84\\xe5\\xba\\x97\\xe8\\xbf\\x87 \\xe6\\x83\\xb3\\xe9\\xbb\\x99\\xe8\\xbf\\x98\\xe5\\xad\\x90 \\xe5\\xa8\\x9e\\xe5\\xad\\x90\\xe6\\x88\\x91\\xe6\\x97\\xa0\\xe5\\xb7\\xb2\\xe7\\xbb')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f \\xe8\\xaf\\x9e\\xe6\\x88\\x90\\xe4\\xba\\x86\\xe8\\xbf\\x99\\xe8\\x91\\x97\\xe5\\x88\\xb0 \\xe4\\xb8\\x89\\xe5\\x88\\xb9\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe7\\x94\\x9c\\xe7\\x8b\\xbc \\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xbf\\x81\\xe6\\x8a\\x91\\xe4\\xbd\\xa0 \\xe5\\x9c\\xa8\\xe6\\x88\\x91\\xe6\\x83\\xb8\\xe8\\xa6\\x81\\xe5\\xbf\\x83\\xe6\\x88\\x91 \\xe7\\xae\\xa9\\xe6\\x88\\x91 \\xe6\\x88\\x91\\xe7\\x88\\xb1\\xe4\\xbd\\xa0\\xe7\\x9a\\x84\\xe7\\x88\\xb1\\xe5\\x86\\x99\\xe5\\x9c')\n",
      "()\n",
      "Epoch 100. Training perplexity 1.223318\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\xbb \\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe5\\xa4\\xa9\\xe7\\xa9\\xba \\xe6\\xb8\\xbb\\xe9\\x87\\xa8\\xe8\\xbf\\x99\\xe9\\xa3\\x8e \\xe5\\x9c\\xa8\\xe5\\xa4\\x9a\\xe5\\xb9\\xb4\\xe4\\xbb\\xa5\\xe5\\x90\\x8e \\xe8\\xbf\\x98\\xe6\\x98\\xaf\\xe8\\xae\\xa9\\xe4\\xba\\xba\\xe9\\x9a\\xbe\\xe8\\xbf\\x87 \\xe5\\xbf\\x83\\xe4\\xbc\\xa4\\xe9\\x80\\x8f \\xe5\\xa8\\x98\\xe5\\xad\\x90\\xe5\\xa5\\xb9\\xe4\\xba\\xba\\xe5\\x9c\\xa8\\xe6\\xb1\\x9f\\xe5\\x8d\\x97\\xe7\\xad\\x89\\xe6\\x88')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80 \\xe6\\xaf\\xa5\\xe8\\xb0\\xb0\\xe8\\xaf\\xb4\\xe6\\x88\\x91 \\xe5\\x9c\\xa8\\xe6\\x98\\xaf\\xe6\\x9d\\xa5\\xe4\\xb8\\x8d\\xe6\\x83\\xb3\\xe5\\xa4\\x9a \\xe8\\xbf\\x98\\xe8\\x83\\xbd\\xe5\\xa4\\xaa\\xe5\\xbd\\xa0\\xe5\\xbd\\x93\\xe5\\x88\\xb1 \\xe8\\xae\\xa9\\xe4\\xbd\\xa0\\xe7\\x9c\\xbc\\xe7\\x9d\\x80\\xe7\\x9c\\x8b \\xe6\\x88\\x91\\xe8\\xaf\\xb4\\xe5\\xa5\\xbd\\xe5\\x8f\\xb2\\xe7\\x9a\\x84\\xe6\\x99\\xaa\\xe6\\xac\\x91\\xe9\\xa9\\xbd\\xe9\\xbb\\x98\\xe7\\x9a\\x84\\xe8\\xaf\\x9d')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f \\xe8\\xaf\\x9d\\xe5\\x95\\x8c\\xe5\\xae\\x9e\\xe5\\xae\\x9e\\xe5\\xae\\xbb \\xe8\\xaf\\x81\\xe6\\x88\\x91\\xe7\\x83\\xbd\\xe6\\x88\\x91 \\xe6\\x88\\x91\\xe6\\x80\\x95\\xe4\\xbd\\xa0\\xe8\\x9c\\x89\\xe6\\x88\\x91\\xe5\\x89\\x8b\\xe5\\x9c\\xa8 \\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x92\\x8c\\xe4\\xbd\\xa0\\xe9\\x9e\\x9e\\xe5\\x88\\xb1\\xe5\\xae\\x95\\xe4\\xb8\\x80\\xe5\\xa4\\x9a \\xe5\\x8c\\x97\\xe5\\xba\\xba\\xe5\\x9b\\x83\\xe5\\x8f\\xaf\\xe7\\x9a\\xb1\\xe6\\x88\\x91 \\xe6\\x88')\n",
      "()\n",
      "Epoch 120. Training perplexity 1.112985\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\xbb \\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x92\\x8c\\xe4\\xbd\\xa0\\xe8\\x9e\\x8d\\xe5\\x8c\\x96\\xe5\\x9c\\xa8\\xe4\\xb8\\x80\\xe8\\xb5\\xb7 \\xe8\\x9e\\x8d\\xe5\\x8c\\x96\\xe5\\x9c\\xa8\\xe5\\xae\\x87\\xe5\\xae\\x99\\xe9\\x87\\x8c \\xe6\\x88\\x91\\xe6\\xaf\\x8f\\xe5\\xa4\\xa9\\xe6\\xaf\\x8f\\xe5\\xa4\\xa9\\xe6\\xaf\\x8f\\xe5\\xa4\\xa9\\xe5\\x9c\\xa8\\xe6\\x83\\xb3\\xe6\\x83\\xb3\\xe6\\x83\\xb3\\xe6\\x83\\xb3\\xe8\\x91\\x97\\xe4\\xbd\\xa0 \\xe8\\xbf\\x99\\xe6\\xa0\\xb7\\xe7')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80\\x9a\\x84\\xe7\\x9a\\x84\\xe8\\xbd\\xbd\\xe8\\x9c\\xa8\\xe9\\x9d\\x8f\\xe9\\x97\\x9b\\xe8\\xbf\\x87 \\xe7\\xbf\\x8e\\xe7\\x90\\xbf \\xe5\\x85\\xa8\\xe9\\xa2\\xbf\\xe8\\xb7\\xb7\\xe4\\xb8\\x8d\\xe5\\x90\\x8d \\xe5\\xb0\\xb1\\xe5\\xae\\x9e\\xe4\\xb8\\xaa\\xe6\\x96\\xb7\\xe7\\xaf\\x9f\\xe5\\x90\\xa9\\xe6\\x9c\\x89 \\xe4\\xb8\\x8d\\xe7\\x9f\\xa5\\xe5\\x81\\x93\\xe6\\xad\\xa5\\xe6\\x97\\xa1 \\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe8\\x84\\xbd\\xe4\\xbd\\xa0\\xe7\\x9a\\x84\\xe8\\xbf\\x91\\xe7')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f \\xe8\\xaf\\x9d\\xe5\\x88\\x90\\xe5\\x9c\\x9f\\xe5\\xae\\x83\\xe5\\xae\\x99\\xe8\\x80\\x81\\xe6\\xa0\\xa1 \\xe8\\xae\\x9e\\xe6\\xb3\\xaa\\xe5\\xbe\\x8e\\xe7\\xb9\\x9f\\xe5\\x90\\x8e\\xe7\\x94\\xbb\\xe5\\xbc\\x81\\xe7\\x9a\\x84\\xe8\\xaa\\xa9\\xe8\\xa8\\x80 \\xe4\\xb8\\x80\\xe5\\x88\\x87\\xe5\\x8f\\x88\\xe9\\x87\\x8d\\xe6\\xbc\\x94 \\xe7\\xa5\\xad\\xe5\\x8f\\xb8 \\xe7\\xa5\\x9e\\xe6\\xae\\xbf \\xe5\\xbe\\x81\\xe6\\x88\\x98 \\xe5\\xbc\\x93\\xe7\\xae\\xad \\xe6\\x98\\xaf')\n",
      "()\n",
      "Epoch 140. Training perplexity 1.073142\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\xbb \\xe6\\x83\\xb3\\xe8\\xa6\\x81\\xe5\\x92\\x8c\\xe4\\xbd\\xa0\\xe8\\x9e\\x8d\\xe5\\x8c\\x96\\xe5\\x9c\\xa8\\xe4\\xb8\\x80\\xe6\\xb5\\xb7 \\xe8\\xaf\\xb4\\xe6\\x95\\x9c \\xe7\\x9c\\x9b\\xe4\\xb8\\x8d\\xe9\\x82\\xa2\\xe7\\x9a\\x84\\xe9\\xac\\xa8 \\xe5\\xbe\\x8e\\xe5\\xb9\\xb0\\xe5\\xa4\\x89\\xe8\\x80\\x81\\xe6\\x96\\x91\\xe9\\xb8\\xa0 \\xe8\\x85\\xbf\\xe7\\x9f\\xad\\xe6\\xaf\\x9b\\xe4\\xb8\\x8d\\xe5\\xa4\\x9a \\xe5\\x87\\xa0\\xe5\\xa4\\xa9\\xe9\\x83\\xbd\\xe6\\xb2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\x9f \\xe6\\x9c\\xa5\\xe8\\xaf\\x81\\xe5\\xb1\\xba\\xe4\\xb9\\x88 \\xe4\\xb8\\x8d\\xe9\\x87\\xa5\\xe8\\xaf\\xb9\\xe7\\xa5\\x9e\\xe6\\x88\\x91 \\xe5\\x9b\\xb3\\xe5\\xa4\\xb4\\xe8\\xbf\\x99\\xe9\\x9a\\xbe\\xe8\\xbe\\xbd\\xe4\\xb8\\x8a\\xe8\\x83\\xbd\\xe8\\xaf\\x92 \\xe6\\x88\\x91\\xe6\\x89\\xa5\\xe4\\xbd\\xa0\\xe7\\x9a\\x84\\xe5\\xad\\x97\\xe8\\xa2\\xb2 \\xe5\\x88\\xab\\xe4\\xba\\xba\\xe7\\x9a\\x84\\xe6\\x88\\x91 \\xe5\\x9b\\xa8\\xe5\\x9c\\xb0\\xe5\\x8f\\x91\\xe7\\x8e')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f\\xe6\\x98\\xaf\\xe8\\xbd\\xb4\\xe5\\xa5\\xbd \\xe8\\xbf\\x99\\xe4\\xbb\\xa5\\xe4\\xb8\\x8a\\xe6\\x88\\x91 \\xe8\\xaf\\xb4\\xe4\\xbd\\xa0\\xe7\\x9b\\x84\\xe7\\xbe\\x8e \\xe5\\x9c\\xa8\\xe9\\xa3\\x91\\xe8\\xbf\\xab\\xe6\\x96\\x90\\xe5\\x86\\xb3\\xe5\\xa6\\xbb \\xe5\\xae\\x83\\xe7\\xa9\\xa0\\xe5\\x86\\xad\\xe8\\xbf\\xb5 \\xe4\\xb8\\x80\\xe7\\x88\\x87\\xe4\\xb8\\x8d\\xe6\\x88\\x90 \\xe7\\x9c\\x9f\\xe7\\x9d\\x80\\xe6\\x88\\x91 \\xe5\\x9b\\xb6\\xe5\\x8f\\x91\\xe6\\x96\\x87\\xe5')\n",
      "()\n",
      "Epoch 160. Training perplexity 1.047908\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\xbb \\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe5\\xa4\\xa4\\xe7\\xa9\\xba \\xe6\\x98\\xaf\\xe9\\x9b\\xa8\\xe6\\x98\\xaf\\xe9\\xa3\\x8e \\xe8\\xbf\\x98\\xe6\\x98\\xaf\\xe5\\xbd\\xa9\\xe8\\x99\\xb9 \\xe4\\xbd\\xa0\\xe5\\x9c\\xa8\\xe6\\x93\\x8d\\xe7\\xba\\xb5 \\xe6\\x81\\xa8\\xe8\\x87\\xaa\\xe5\\xb7\\xb1\\xe7\\x9c\\x9f\\xe7\\x9a\\x84\\xe6\\xb2\\xa1\\xe7\\x94\\xa8 \\xe6\\x83\\x85\\xe7\\xbb\\xaa\\xe6\\xbf\\x80\\xe5\\x8a\\xa8 \\xe4\\xb8\\x80\\xe9\\xa2\\x97\\xe5\\xbf\\x83\\xe5')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8f\\xa3\\xe6\\x9c\\x89\\xe8\\xb5\\xb0\\xe5\\xba\\x86\\xe8\\xbf\\x99 \\xe8\\xbf\\x99\\xe4\\xbb\\x91\\xe7\\x9a\\x84\\xe6\\xa2\\xa6 \\xe4\\xb8\\x89\\xe9\\x99\\x87\\xe5\\xa4\\x84\\xe9\\xa3\\x8e \\xe5\\x8f\\x9e\\xe5\\xb0\\xb1\\xe5\\xbd\\xe7\\xe5\\xae\\x8c\\xe5\\x88\\x91\\xe7\\x9d\\xa2\\xe4\\xb8\\x9a\\xe7\\x9a\\x84\\xe5\\x8f\\xaf\\xe7\\x88\\xb1\\xe5\\x9c\\xba\\xe4\\xb9\\x9c\\xe7\\x9a\\x84\\xe4\\xb8\\x8d\\xe5\\xa6\\x88\\xe5\\x90\\x83\\xe5\\x8f\\x97 \\xe6\\x88\\x91\\xe5\\x83\\xb3\\xe9')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f\\xe6\\x9a\\x84\\xe8\\xaf\\xb9 \\xe5\\x9c\\xa8\\xe5\\x9c\\x89\\xe5\\xae\\x89\\xe5\\xa4\\x96\\xe5\\x96\\xb9\\xe6\\x96\\x87\\xe5\\x8a\\x95\\xe5\\x8f\\x91 \\xe6\\x88\\x91\\xe4\\xb8\\x8d\\xe6\\x83\\xb3\\xe5\\xa4\\xaa\\xe7\\xa9\\x8d \\xe6\\x88\\x91\\xe7\\xbb\\x99\\xe4\\xbd\\xa0\\xe7\\x9a\\x84\\xe7\\x88\\xb1\\xe5\\x86\\x99\\xe5\\x9c\\xa8\\xe8\\xa5\\xbf\\xe5\\x85\\x83\\xe5\\x89\\x8d \\xe6\\xb7\\xb1\\xe5\\x9f\\x8b\\xe5\\x9c\\xa8\\xe7\\xbe\\x8e\\xe7\\xb4\\xa2\\xe4\\xb8\\x8d\\xe8\\xbe\\xbe\\xe7')\n",
      "()\n",
      "Epoch 180. Training perplexity 1.036856\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\xbb \\xe4\\xbb\\x99\\xe4\\xba\\xba\\xe6\\x8e\\xb9\\xe6\\x80\\x95\\xe4\\xb9\\x88\\xe9\\x9d\\xa5\\xe6\\x9d\\xa5\\xe8\\x91\\xb0 \\xe5\\xbd\\xb7\\xe6\\x83\\xb3\\xe7\\xba\\xb5\\xe8\\xb5\\xb0\\xe8\\xba\\x9f \\xe4\\xb8\\x8d\\xe8\\xaf\\xb7\\xe5\\xb0\\xb1\\xe5\\x9c\\xa8\\xe4\\x81\\xa0\\xe7\\x9a\\x84\\xe7\\xaa\\xa2\\xe5\\x8d\\x83 \\xe7\\x9c\\x9f\\xe6\\x98\\xaf\\xe6\\xb2\\xb3\\xe6\\x96\\xac\\xe9\\x9e\\xb7\\xe7\\x8b\\xbb\\xe5\\xa4\\xb4 \\xe8\\xbf\\x99\\xe6\\xa0\\xb7\\xe6\\xb2\\xa1')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\x9f \\xe6\\x9c\\xa5\\xe8\\xaf\\xb4\\xe5\\xb1\\xb1\\xe7\\x95\\x9e\\xe5\\xaf\\xb4 \\xe5\\x88\\xab\\xe5\\x88\\xb0\\xe6\\x88\\x91\\xe8\\xa5\\xb8 \\xe5\\x88\\xb0\\xe6\\x83\\xb0\\xe8\\xb5\\xb0\\xe8\\xb5\\xb7\\xe7\\xba\\xbf\\xe6\\xaf\\xad \\xe5\\x8d\\xb4\\xe5\\x8f\\x91\\xe7\\xa9\\xbf\\xe5\\xbf\\x98\\xe5\\xae\\x9a \\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe5\\xa4\\xa7\\xe5\\xa3\\xb0\\xe5\\xae\\xa3\\xe5\\xb8\\x83 \\xe5\\xaf\\xb9\\xe4\\xbd\\xa0\\xe4\\xbe\\x9d\\xe4\\xbe\\x9d\\xe4\\xb8')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f \\xe8\\xaf\\x9d\\xe5\\xa4\\x9f\\xe5\\xae\\x9e\\xe5\\x8c\\x8c\\xe5\\xae\\x87 \\xe4\\xbd\\xa0\\xe4\\xba\\x8b\\xe7\\x88\\x91 \\xe8\\xbf\\x82\\xe4\\xb8\\xba\\xe6\\x83\\xb3\\xe7\\x9a\\x84\\xe5\\xaf\\x97\\xe7\\xa9\\xba \\xe6\\x9c\\x89\\xe4\\xb8\\x80\\xe4\\xb9\\xb2\\xe7\\xba\\xa2 \\xe5\\x90\\x8e\\xe5\\x9c\\xba\\xe5\\x9b\\x95\\xe4\\xba\\x86\\xe6\\x96\\x91\\xe6\\xaf\\x8f\\xe6\\xb0\\xa5\\xe6\\x8a\\xaf\\xe7\\x88\\xb1 \\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe6\\x8f\\xaf\\xe4\\xbd\\xa0\\xe7\\x9a')\n",
      "()\n",
      "Epoch 200. Training perplexity 1.032113\n",
      "(' - ', '\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8e\\xbb \\xe6\\x88\\x91\\xe6\\x83\\xb3\\xe5\\xa6\\x88\\xe8\\xbf\\x87 \\xe5\\x88\\xab\\xe6\\x88\\x91\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe8\\xaf\\x81\\xe6\\x80\\xa5 \\xe4\\xbd\\xa0\\xe6\\x89\\x8b\\xe5\\xbe\\x8e\\xe7\\x9a\\x84\\xe6\\xb2\\xa1\\xe8\\xbe\\xb9 \\xe5\\xb8\\xb8\\xe6\\xad\\x97\\xe8\\xb5\\xb7\\xe4\\xba\\x86\\xe5\\xa4\\x9a\\xe5\\xb9\\xa1 \\xe6\\x98\\xaf\\xe8\\xbd\\xbd\\xe7\\x9a\\x84\\xe6\\x9c\\x8b\\xe8\\xaf\\xb9\\xe5\\x8c\\x9e\\xe5\\x88\\xb0 \\xe6\\x88\\x91\\xe7\\xbb')\n",
      "(' - ', '\\xe4\\xb8\\x8d\\xe5\\x88\\x86\\xe5\\xbc\\x80\\xe5\\x8f\\x91\\xe7\\x9a\\x84\\xe8\\x84\\xbd \\xe5\\xbd\\x9c\\xe8\\x9c\\x8b\\xe7\\x9a\\x84\\xe6\\x88\\x91\\xe4\\xb8\\xba\\xe9\\x9c\\x89\\xe7\\x94\\x9f\\xe4\\xba\\x86 \\xe6\\x88\\x91\\xe5\\x89\\x8d\\xe4\\xb8\\x8d\\xe6\\x8a\\x9b\\xe5\\xa6\\x88\\xe5\\xa6\\x85 \\xe6\\x98\\xaf\\xe8\\xaf\\xa5\\xe7\\x9a\\x84 \\xe5\\xaf\\xb9\\xe9\\x85\\x8b\\xe9\\x95\\xbf\\xe4\\xb8\\x8b\\xe8\\xaf\\x85\\xe5\\x92\\x92 \\xe8\\xbf\\x98\\xe6\\x88\\x91\\xe9\\xaa\\xb7\\xe9\\xab\\x85\\xe5\\xa4\\xb4 \\xe8\\xbf')\n",
      "(' - ', '\\xe6\\x88\\x98\\xe4\\xba\\x89\\xe4\\xb8\\xad\\xe9\\x83\\xa8\\xe9\\x98\\x9f\\xe8\\x91\\x97 \\xe4\\xbb\\x98\\xe8\\xaf\\xb4\\xe8\\xa2\\xb0\\xe5\\x9c\\xa8\\xe9\\xa3\\x8e\\xe5\\x8a\\xa8 \\xe4\\xb8\\x80\\xe7\\x9b\\xb4\\xe5\\x88\\xb0\\xe6\\x88\\x91\\xe7\\x88\\xb8\\xe5\\x88\\xb0\\xe7\\x9a\\x84\\xe7\\x84\\xb6\\xe5\\xae\\xa6 \\xe5\\x9c\\xa8\\xe8\\xa5\\x9d\\xe5\\xa4\\xa9 \\xe5\\x87\\x8c\\xe5\\xa4\\xa4\\xe8\\xbf\\x87\\xe4\\xba\\x86\\xe5\\x88\\xb0\\xe5\\xae\\x83\\xe4\\xbc\\xa4\\xe6\\x80\\x9d\\xe5\\x85\\xb1\\xe6\\xad\\xa5\\xe8\\x86\\x8d\\xe6\\x84\\xb3\\xe5\\x8a\\xa8 ')\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "seq1 = '分开'\n",
    "seq2 = '不分开'\n",
    "seq3 = '战争中部队'\n",
    "seqs = [seq1, seq2, seq3]\n",
    "\n",
    "utils.train_and_predict_rnn(rnn=lstm_rnn, is_random_iter=False, epochs=200,\n",
    "                            num_steps=35, hidden_dim=hidden_dim, \n",
    "                            learning_rate=0.2, clipping_norm=5,\n",
    "                            batch_size=32, pred_period=20, pred_len=100,\n",
    "                            seqs=seqs, get_params=get_params,\n",
    "                            get_inputs=get_inputs, ctx=ctx,\n",
    "                            corpus_indices=corpus_indices,\n",
    "                            idx_to_char=idx_to_char, char_to_idx=char_to_idx,\n",
    "                            is_lstm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到一开始学到简单的字符，然后简单的词，接着是复杂点的词，然后看上去似乎像个句子了。\n",
    "\n",
    "## 结论\n",
    "\n",
    "* 长短期记忆的提出是为了更好地捕捉时序数据中间隔较大的依赖关系。\n",
    "* 长短期记忆的结构比门控循环单元的结构较复杂。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 调调参数（例如数据集大小、序列长度、隐含状态长度和学习率），看看对运行时间、perplexity和预测的结果造成的影响。\n",
    "* 在相同条件下，比较长短期记忆和门控循环单元以及循环神经网络的运行效率。\n",
    "\n",
    "**吐槽和讨论欢迎点**[这里](https://discuss.gluon.ai/t/topic/4042)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

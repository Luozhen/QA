{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG：使用重复元素的非常深的网络\n",
    "\n",
    "我们从Alexnet看到网络的层数的激增。这个意味着即使是用Gluon手动写代码一层一层的堆每一层也很麻烦，更不用说从0开始了。幸运的是编程语言提供了很好的方法来解决这个问题：函数和循环。如果网络结构里面有大量重复结构，那么我们可以很紧凑来构造这些网络。第一个使用这种结构的深度网络是VGG。\n",
    "\n",
    "## VGG架构\n",
    "\n",
    "VGG的一个关键是使用很多有着相对小的kernel（$3\\times 3$）的卷积层然后接上一个池化层，之后再将这个模块重复多次。下面我们先定义一个这样的块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "def vgg_block(num_convs, channels):\n",
    "    out = nn.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        out.add(\n",
    "            nn.Conv2D(channels=channels, kernel_size=3,\n",
    "                      padding=1, activation='relu')\n",
    "        )\n",
    "    out.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们实例化一个这样的块，里面有两个卷积层，每个卷积层输出通道是128："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 128, 8, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "\n",
    "blk = vgg_block(2, 128)\n",
    "blk.initialize()\n",
    "x = nd.random.uniform(shape=(2,3,16,16))\n",
    "y = blk(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到经过一个这样的块后，长宽会减半，通道也会改变。\n",
    "\n",
    "然后我们定义如何将这些块堆起来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_stack(architecture):\n",
    "    out = nn.Sequential()\n",
    "    for (num_convs, channels) in architecture:\n",
    "        out.add(vgg_block(num_convs, channels))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们定义一个最简单的一个VGG结构，它有8个卷积层，和跟Alexnet一样的3个全连接层。这个网络又称VGG 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 10\n",
    "architecture = ((1,64), (1,128), (2,256), (2,512), (2,512))\n",
    "net = nn.Sequential()\n",
    "# add name_scope on the outermost Sequential\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        vgg_stack(architecture),\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(4096, activation=\"relu\"),\n",
    "        nn.Dropout(.5),\n",
    "        nn.Dense(4096, activation=\"relu\"),\n",
    "        nn.Dropout(.5),\n",
    "        nn.Dense(num_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "这里跟Alexnet的训练代码一样除了我们只将图片扩大到$96\\times 96$来节省些计算，和默认使用稍微大点的学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on  gpu(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.867, Train acc 0.68, Test acc 0.85, Time 140.6 sec\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "\n",
    "train_data, test_data = utils.load_data_fashion_mnist(\n",
    "    batch_size=64, resize=96)\n",
    "\n",
    "ctx = utils.try_gpu()\n",
    "net.initialize(ctx=ctx, init=init.Xavier())\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), \n",
    "                        'sgd', {'learning_rate': 0.05})\n",
    "utils.train(train_data, test_data, net, loss,\n",
    "            trainer, ctx, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "通过使用重复的元素，我们可以通过循环和函数来定义模型。使用不同的配置(`architecture`)可以得到一系列不同的模型。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "- 尝试多跑几轮，看看跟LeNet/Alexnet比怎么样？\n",
    "- 尝试下构造VGG其他常用模型，例如VGG16， VGG19. （提示：可以参考[VGG论文](https://arxiv.org/abs/1409.1556)里的表1。）\n",
    "- 把图片从默认的$224\\times 224$降到$96\\times 96$有什么影响？\n",
    "\n",
    "\n",
    "**吐槽和讨论欢迎点**[这里](https://discuss.gluon.ai/t/topic/1277)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}